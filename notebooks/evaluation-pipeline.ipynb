{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Pipeline\n",
    "\n",
    "This notebook evaluates both the baseline Whisper-small model and the fine-tuned model on the Hindi FLEURS test dataset.\n",
    "\n",
    "## Steps:\n",
    "1. Load FLEURS Hindi test dataset\n",
    "2. Evaluate baseline Whisper-small\n",
    "3. Load fine-tuned model from Hugging Face\n",
    "4. Evaluate fine-tuned model\n",
    "5. Compare results and generate report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T07:11:08.331867Z",
     "iopub.status.busy": "2025-11-02T07:11:08.331229Z",
     "iopub.status.idle": "2025-11-02T07:11:15.121188Z",
     "shell.execute_reply": "2025-11-02T07:11:15.120280Z",
     "shell.execute_reply.started": "2025-11-02T07:11:08.331834Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\n",
      "pathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
      "diffusers 0.34.0 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.20.0 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "peft 0.16.0 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.20.0 which is incompatible.\n",
      "gradio 5.38.1 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.20.0 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\n",
      "transformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 0.20.0 which is incompatible.\n",
      "accelerate 1.9.0 requires huggingface_hub>=0.21.0, but you have huggingface-hub 0.20.0 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q \"datasets==2.16.0\" \"huggingface-hub==0.20.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T07:12:28.873257Z",
     "iopub.status.busy": "2025-11-02T07:12:28.872606Z",
     "iopub.status.idle": "2025-11-02T07:13:57.080900Z",
     "shell.execute_reply": "2025-11-02T07:13:57.079972Z",
     "shell.execute_reply.started": "2025-11-02T07:12:28.873227Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.8/375.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U -q transformers  accelerate evaluate jiwer  soundfile librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T07:14:03.351505Z",
     "iopub.status.busy": "2025-11-02T07:14:03.350740Z",
     "iopub.status.idle": "2025-11-02T07:14:26.407402Z",
     "shell.execute_reply": "2025-11-02T07:14:26.406764Z",
     "shell.execute_reply.started": "2025-11-02T07:14:03.351474Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 07:14:13.185692: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762067653.384879      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762067653.441085      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7cccb653b2d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    WhisperProcessor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    pipeline\n",
    ")\n",
    "import evaluate\n",
    "from huggingface_hub import login\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv()\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T07:14:31.424810Z",
     "iopub.status.busy": "2025-11-02T07:14:31.424168Z",
     "iopub.status.idle": "2025-11-02T07:14:31.584224Z",
     "shell.execute_reply": "2025-11-02T07:14:31.583574Z",
     "shell.execute_reply.started": "2025-11-02T07:14:31.424789Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Logged in to Hugging Face\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    'baseline_model': 'openai/whisper-small',\n",
    "    'finetuned_model': 'datafreak/whisper-hindi',\n",
    "    'language': 'hi',\n",
    "    'batch_size': 4,\n",
    "    'results_dir': '../results',\n",
    "}\n",
    "\n",
    "# Login to Hugging Face\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\", \"<HF_TOKEN_PLACEHOLDER>\")\n",
    "if HF_TOKEN and HF_TOKEN != \"<HF_TOKEN_PLACEHOLDER>\":\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"✓ Logged in to Hugging Face\")\n",
    "else:\n",
    "    print(\"⚠ HF_TOKEN not provided. Set the environment variable before publishing artifacts.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs(CONFIG['results_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load FLEURS Hindi Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T07:14:35.820683Z",
     "iopub.status.busy": "2025-11-02T07:14:35.820168Z",
     "iopub.status.idle": "2025-11-02T07:15:05.388837Z",
     "shell.execute_reply": "2025-11-02T07:15:05.388037Z",
     "shell.execute_reply.started": "2025-11-02T07:14:35.820660Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FLEURS Hindi dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5d6bc412b6444cb8ef8a02f5df456c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db39c45ef6a34504830523c6cce0057f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting test split to dataset...\n",
      "✓ Loaded 418 test samples\n",
      "\n",
      "Dataset features: {'id': Value(dtype='int64', id=None), 'num_samples': Value(dtype='int64', id=None), 'path': Value(dtype='null', id=None), 'audio': {'array': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), 'path': Value(dtype='string', id=None), 'sampling_rate': Value(dtype='int64', id=None)}, 'transcription': Value(dtype='string', id=None), 'raw_transcription': Value(dtype='string', id=None), 'gender': Value(dtype='int64', id=None), 'lang_id': Value(dtype='int64', id=None), 'language': Value(dtype='string', id=None), 'lang_group_id': Value(dtype='int64', id=None)}\n",
      "\n",
      "First transcription: कुछ अणुओं में अस्थिर केंद्रक होता है जिसका मतलब यह है कि उनमें थोड़े या बिना किसी झटके से टूटने की प्रवृत्ति होती है\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "print(\"Loading FLEURS Hindi dataset...\")\n",
    "\n",
    "# Stream and collect test data\n",
    "fleurs_asr = load_dataset(\"google/fleurs\", \"hi_in\", streaming=True)\n",
    "\n",
    "print(\"Converting test split to dataset...\")\n",
    "test_samples = list(fleurs_asr[\"test\"])\n",
    "fleurs_dataset = Dataset.from_list(test_samples)\n",
    "\n",
    "print(f\"✓ Loaded {len(fleurs_dataset)} test samples\")\n",
    "print(f\"\\nDataset features: {fleurs_dataset.features}\")\n",
    "\n",
    "# Now use it like normal\n",
    "audio_input = fleurs_dataset[0][\"audio\"]\n",
    "transcription = fleurs_dataset[0][\"transcription\"]\n",
    "print(f\"\\nFirst transcription: {transcription}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T07:15:11.160738Z",
     "iopub.status.busy": "2025-11-02T07:15:11.159992Z",
     "iopub.status.idle": "2025-11-02T07:15:11.168032Z",
     "shell.execute_reply": "2025-11-02T07:15:11.167336Z",
     "shell.execute_reply.started": "2025-11-02T07:15:11.160712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, dataset, batch_size=16):\n",
    "    \"\"\"\n",
    "    Evaluate a Whisper model on the given dataset.\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating model: {model_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load model and processor\n",
    "    processor = WhisperProcessor.from_pretrained(model_name)\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Configure generation\n",
    "    model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(\n",
    "        language=\"hindi\", \n",
    "        task=\"transcribe\"\n",
    "    )\n",
    "    \n",
    "    # Prepare predictions and references\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    # Whisper expects 30 seconds of audio at 16kHz = 480,000 samples\n",
    "    MAX_AUDIO_LENGTH = 30 * 16000  # 30 seconds at 16kHz sampling rate\n",
    "    \n",
    "    # Process in batches\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(dataset), batch_size), desc=\"Evaluating\"):\n",
    "            batch = dataset[i:i+batch_size]\n",
    "            \n",
    "            # Extract audio\n",
    "            audio_arrays = [item['array'] for item in batch['audio']]\n",
    "            \n",
    "            # Process audio with correct max_length for audio samples\n",
    "            inputs = processor(\n",
    "                audio_arrays,\n",
    "                sampling_rate=16000,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"max_length\",\n",
    "                max_length=MAX_AUDIO_LENGTH,  # This is in audio samples, not mel frames\n",
    "                truncation=True\n",
    "            )\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            # Generate transcriptions\n",
    "            generated_ids = model.generate(inputs.input_features)\n",
    "            transcriptions = processor.batch_decode(\n",
    "                generated_ids, \n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "            \n",
    "            predictions.extend(transcriptions)\n",
    "            references.extend(batch['transcription'])\n",
    "    \n",
    "    # Calculate WER\n",
    "    wer_metric = evaluate.load(\"wer\")\n",
    "    wer = 100 * wer_metric.compute(predictions=predictions, references=references)\n",
    "    \n",
    "    print(f\"\\n✓ Evaluation complete\")\n",
    "    print(f\"  WER: {wer:.2f}%\")\n",
    "    print(f\"  Total samples: {len(predictions)}\")\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'wer': wer,\n",
    "        'predictions': predictions,\n",
    "        'references': references,\n",
    "        'num_samples': len(predictions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T07:15:18.454697Z",
     "iopub.status.busy": "2025-11-02T07:15:18.454448Z",
     "iopub.status.idle": "2025-11-02T07:24:26.223146Z",
     "shell.execute_reply": "2025-11-02T07:24:26.222515Z",
     "shell.execute_reply.started": "2025-11-02T07:15:18.454680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model: openai/whisper-small\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29b5fac95414c8ea66da03f510aea24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25f41ec24e8417890ed667218344bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93cc4e0d69b4e40afb7f810e27a2df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd1dd4fd19e40ffb739c6f1e2436037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2c13359ade473d9e3195f0795ec346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0dd866576e4779830fadb82243577a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80f7e8c3cbe41bdb37cc15e5f6049ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce77e7308b144f79b58c8082ee9a7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a293b3803cf44cb79c370fa67f4dbb18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4336e6959a4df8845e46f51375c6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923aee073d4e450b8d3375685bc1d4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/105 [00:00<?, ?it/s]Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Evaluating: 100%|██████████| 105/105 [09:00<00:00,  5.15s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81540e6617c54164b9f5fa3a91b60ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Evaluation complete\n",
      "  WER: 84.64%\n",
      "  Total samples: 418\n"
     ]
    }
   ],
   "source": [
    "baseline_results = evaluate_model(\n",
    "    CONFIG['baseline_model'],\n",
    "    fleurs_dataset,\n",
    "    batch_size=CONFIG['batch_size']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T07:25:24.539703Z",
     "iopub.status.busy": "2025-11-02T07:25:24.538939Z",
     "iopub.status.idle": "2025-11-02T07:31:27.423389Z",
     "shell.execute_reply": "2025-11-02T07:31:27.422605Z",
     "shell.execute_reply.started": "2025-11-02T07:25:24.539676Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model: datafreak/whisper-hindi\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d0466552af4695b9755a5e40a03e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/356 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b7acab8edb4fe6ac0fc7f8b9b7c33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10533c97d2aa456287b80bb0544c2d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96ede1ccc6a44d28140471565d71a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3d06469b2f4686be599db15d86c973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccde097437474b77977bd6a79969d9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e9dd1cc5e9408e8d767e2f6fd2a75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1d36a3b2584e01ba310c076377fb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9293d20391b5418fa7250861a7f7524a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ed51f51e2f46258c7ff47625810a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/105 [00:00<?, ?it/s]`generation_config` default values have been modified to match model-specific defaults: {'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}. If this is not desired, please set these values explicitly.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> to see related `.generate()` flags.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> to see related `.generate()` flags.\n",
      "Evaluating: 100%|██████████| 105/105 [05:55<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Evaluation complete\n",
      "  WER: 38.20%\n",
      "  Total samples: 418\n"
     ]
    }
   ],
   "source": [
    "finetuned_results = evaluate_model(\n",
    "    CONFIG['finetuned_model'],\n",
    "    fleurs_dataset,\n",
    "    batch_size=CONFIG['batch_size']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T07:31:39.761751Z",
     "iopub.status.busy": "2025-11-02T07:31:39.761450Z",
     "iopub.status.idle": "2025-11-02T07:31:39.783816Z",
     "shell.execute_reply": "2025-11-02T07:31:39.783061Z",
     "shell.execute_reply.started": "2025-11-02T07:31:39.761730Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS - FLEURS Hindi Test Set\n",
      "============================================================\n",
      "\n",
      "                     Model WER (%)  Test Samples\n",
      "  Baseline (whisper-small)   84.64           418\n",
      "Fine-tuned (whisper-hindi)   38.20           418\n",
      "\n",
      "============================================================\n",
      "WER Improvement: 46.45 percentage points\n",
      "Relative Improvement: 54.87%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': 'Baseline (whisper-small)',\n",
    "        'WER (%)': f\"{baseline_results['wer']:.2f}\",\n",
    "        'Test Samples': baseline_results['num_samples']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Fine-tuned (whisper-hindi)',\n",
    "        'WER (%)': f\"{finetuned_results['wer']:.2f}\",\n",
    "        'Test Samples': finetuned_results['num_samples']\n",
    "    }\n",
    "])\n",
    "\n",
    "# Calculate improvement\n",
    "wer_improvement = baseline_results['wer'] - finetuned_results['wer']\n",
    "relative_improvement = (wer_improvement / baseline_results['wer']) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION RESULTS - FLEURS Hindi Test Set\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"WER Improvement: {wer_improvement:.2f} percentage points\")\n",
    "print(f\"Relative Improvement: {relative_improvement:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T07:31:45.181955Z",
     "iopub.status.busy": "2025-11-02T07:31:45.181389Z",
     "iopub.status.idle": "2025-11-02T07:31:45.200899Z",
     "shell.execute_reply": "2025-11-02T07:31:45.200378Z",
     "shell.execute_reply.started": "2025-11-02T07:31:45.181933Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Comparison table saved to: ../results/wer_comparison.csv\n",
      "✓ Detailed predictions saved to: ../results/detailed_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save comparison table\n",
    "comparison_df.to_csv(f\"{CONFIG['results_dir']}/wer_comparison.csv\", index=False)\n",
    "print(f\"✓ Comparison table saved to: {CONFIG['results_dir']}/wer_comparison.csv\")\n",
    "\n",
    "# Save detailed results\n",
    "detailed_results = pd.DataFrame({\n",
    "    'reference': baseline_results['references'],\n",
    "    'baseline_prediction': baseline_results['predictions'],\n",
    "    'finetuned_prediction': finetuned_results['predictions']\n",
    "})\n",
    "detailed_results.to_csv(f\"{CONFIG['results_dir']}/detailed_predictions.csv\", index=False)\n",
    "print(f\"✓ Detailed predictions saved to: {CONFIG['results_dir']}/detailed_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T07:31:48.926570Z",
     "iopub.status.busy": "2025-11-02T07:31:48.925861Z",
     "iopub.status.idle": "2025-11-02T07:31:50.298811Z",
     "shell.execute_reply": "2025-11-02T07:31:50.298242Z",
     "shell.execute_reply.started": "2025-11-02T07:31:48.926546Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded ../results/wer_comparison.csv to hf://datafreak/whisper-hindi-eval-results/results/wer_comparison.csv\n",
      "✓ Uploaded ../results/detailed_predictions.csv to hf://datafreak/whisper-hindi-eval-results/results/detailed_predictions.csv\n",
      "All artifacts available at: https://huggingface.co/datasets/datafreak/whisper-hindi-eval-results\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, HfFolder\n",
    "from pathlib import Path\n",
    "\n",
    "api = HfApi()\n",
    "token = HF_TOKEN if HF_TOKEN and HF_TOKEN != \"<HF_TOKEN_PLACEHOLDER>\" else HfFolder.get_token()\n",
    "if not token:\n",
    "    raise RuntimeError(\"No Hugging Face token available. Run the earlier login cell with a valid token.\")\n",
    "\n",
    "user_info = api.whoami(token)\n",
    "username = user_info.get(\"name\") or user_info.get(\"displayName\")\n",
    "if not username:\n",
    "    raise RuntimeError(\"Unable to determine Hugging Face username from the configured token.\")\n",
    "\n",
    "repo_name = \"whisper-hindi-eval-results\"\n",
    "repo_id = f\"{username}/{repo_name}\"\n",
    "repo_type = \"dataset\"\n",
    "\n",
    "api.create_repo(\n",
    "    repo_id=repo_id,\n",
    "    repo_type=repo_type,\n",
    "    token=token,\n",
    "    private=False,\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "files_to_upload = {\n",
    "    Path(\"../results/wer_comparison.csv\"): \"results/wer_comparison.csv\",\n",
    "    Path(\"../results/detailed_predictions.csv\"): \"results/detailed_predictions.csv\",\n",
    "}\n",
    "\n",
    "for local_path, repo_path in files_to_upload.items():\n",
    "    if not local_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing artifact: {local_path}\")\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=local_path,\n",
    "        path_in_repo=repo_path,\n",
    "        repo_id=repo_id,\n",
    "        repo_type=repo_type,\n",
    "        token=token\n",
    "    )\n",
    "    print(f\"✓ Uploaded {local_path} to hf://{repo_id}/{repo_path}\")\n",
    "\n",
    "print(f\"All artifacts available at: https://huggingface.co/datasets/{repo_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sample Predictions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T06:52:50.896907Z",
     "iopub.status.busy": "2025-11-02T06:52:50.896638Z",
     "iopub.status.idle": "2025-11-02T06:52:50.905538Z",
     "shell.execute_reply": "2025-11-02T06:52:50.904658Z",
     "shell.execute_reply.started": "2025-11-02T06:52:50.896887Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAMPLE PREDICTIONS\n",
      "============================================================\n",
      "\n",
      "Sample 270:\n",
      "------------------------------------------------------------\n",
      "Reference:\n",
      "  तूफान और बवंडर की तरह आंधी ओले भारी बारिश और जंगल की आग तीव्र मौसम का हिस्सा और असर हैं\n",
      "\n",
      "Baseline:\n",
      "   तूफान और भवन्दर की तड़ा आन्दि ओले भारी भारिश और जंगल की आख तीव्र मोसम का हिस्था और असर है\n",
      "\n",
      "Fine-tuned:\n",
      "  तुफान और भवंदर की तरह आंधी ओले भारी भारिश और जंगल की आग तीव्र मौसम का हिस्सा और असर है\n",
      "------------------------------------------------------------\n",
      "\n",
      "Sample 396:\n",
      "------------------------------------------------------------\n",
      "Reference:\n",
      "  उदाहरण के लिए दुनिया में सबसे ज़्यादा इस्तेमाल होने वाला फ़ोटोग्राफ़ी फ़ॉर्मेट 35mm है यह एनालॉग फिल्म दौर के आखिर में काफी प्रचलित था\n",
      "\n",
      "Baseline:\n",
      "   उदाहरन के लिए तुन्यमें सब सी जाडा इस्तमाल होनी वाला फोटोग्राफी फोरमेट पैटिस मेंव है यहा एना लोग फिर्मे दोर के आखिर में काफी प्रचलीते ते ता\n",
      "\n",
      "Fine-tuned:\n",
      "  उदाहरन के लिए तूनिया में सबसी ज्यादा इस्तमाल होनी वाला फोटोग्राफी फॉर्मेट पैंतिस एमम है यहां एना लोग फिर में दौड़ के आखीर में काफी प्रचलीते था\n",
      "------------------------------------------------------------\n",
      "\n",
      "Sample 22:\n",
      "------------------------------------------------------------\n",
      "Reference:\n",
      "  कुछ लोगों ये सोचते थे की कि वह सही था लेकिन बहुत से लोग इसके विपरीत मानते थे; की सौर मंडल सूर्य और यहां तक कि अन्य सितारों सहित पृथ्वी के चारों और चक्कर लगता था ।\n",
      "\n",
      "Baseline:\n",
      "   पुच लोग ये सुर्स थे खी की ये सही ता लेकिन बहुच्से लोग इसके विप्रित मानते थे की सूर मंडल सूर्य अग़् और यहाद तक की अन सितारे सहीट प्रिष्वी के चारो और चकर लगाता था\n",
      "\n",
      "Fine-tuned:\n",
      "  कुछ लोग यह सोर्स थे कि कि यह सही था लेकिन बहुत से लोग इसके विप्रित मानते थे कि इस सोर मंडल फूरी और यहां तक की अन्य सितारे सहीत प्रित्सवी के चारों और चक्कर लगाता था\n",
      "------------------------------------------------------------\n",
      "\n",
      "Sample 257:\n",
      "------------------------------------------------------------\n",
      "Reference:\n",
      "  परिसर के किनारे ज़्यादातर इमारतें फिर से बनाई गई हैं ताकि पर्यटकों को बेहतर ढंग से पता चल सके कि वे मूल रूप में कैसी दिखाई देती थी\n",
      "\n",
      "Baseline:\n",
      "   परिसर की किनारे से आतातर इमारते फिर से बनाई गई हैं ताकि परिटोख हूँ को बहतर द्यांग से पता चले कि वे मूल रूप में कैसी दिखाई दिती थी.\n",
      "\n",
      "Fine-tuned:\n",
      "  परिशर के किनारे से आतातर इमाड़ते फिर से बनाई गई हैं ताकि परिटो को बेहतर धंग से पता चले कि वे मूल रूप में कैसी दिखा ही देती थी\n",
      "------------------------------------------------------------\n",
      "\n",
      "Sample 172:\n",
      "------------------------------------------------------------\n",
      "Reference:\n",
      "  बेशक इस परंपरा के पीछे ईसाई धर्मशास्त्र के स्पष्टीकरण दिए जाते हैं लेकिन एक प्री-क्रिश्चयन स्प्रिंग और फ़र्टिलिटी रस्म भी हो सकती है\n",
      "\n",
      "Baseline:\n",
      "   बेसक इस परमपरके पिछे इशाई दर्मसाश्तरों के सबस्टिकरन दिये जाते है, लेकिन एक प्री कुष्चिन श्प्रिंग और पर्टिलीटी रसम भी हो सकती है.\n",
      "\n",
      "Fine-tuned:\n",
      "  बेशक इस परंपरक के पीछे इशाई धर्मसास्त्रों के स्पस्ट करन दिया जाता है लेकिन एक प्री कुश्चन स्प्रिंग और फर्टिलीटी रसम भी हो सकती है\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show 5 random samples\n",
    "sample_indices = np.random.choice(len(detailed_results), 5, replace=False)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    print(f\"\\nSample {idx + 1}:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Reference:\\n  {detailed_results.iloc[idx]['reference']}\")\n",
    "    print(f\"\\nBaseline:\\n  {detailed_results.iloc[idx]['baseline_prediction']}\")\n",
    "    print(f\"\\nFine-tuned:\\n  {detailed_results.iloc[idx]['finetuned_prediction']}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T06:53:08.013872Z",
     "iopub.status.busy": "2025-11-02T06:53:08.013418Z",
     "iopub.status.idle": "2025-11-02T06:53:08.019971Z",
     "shell.execute_reply": "2025-11-02T06:53:08.019293Z",
     "shell.execute_reply.started": "2025-11-02T06:53:08.013847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Final report saved to: ../results/evaluation_report.md\n",
      "\n",
      "\n",
      "# Whisper-Small Hindi ASR Evaluation Report\n",
      "\n",
      "## Dataset\n",
      "- **Test Set**: FLEURS Hindi (google/fleurs, hi_in split)\n",
      "- **Number of Samples**: 418\n",
      "\n",
      "## Models Evaluated\n",
      "1. **Baseline**: openai/whisper-small\n",
      "2. **Fine-tuned**: datafreak/whisper-hindi\n",
      "\n",
      "## Results\n",
      "\n",
      "| Model | WER (%) |\n",
      "|-------|--------|\n",
      "| Baseline (whisper-small) | 84.64 |\n",
      "| Fine-tuned (whisper-hindi) | 38.20 |\n",
      "\n",
      "## Performance Improvement\n",
      "- **Absolute WER Reduction**: 46.45 percentage points\n",
      "- **Relative Improvement**: 54.87%\n",
      "\n",
      "## Conclusion\n",
      "The fine-tuned model improved over the baseline model on the FLEURS Hindi test set.\n",
      "\n",
      "---\n",
      "Generated using evaluation_pipeline.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = f\"\"\"\n",
    "# Whisper-Small Hindi ASR Evaluation Report\n",
    "\n",
    "## Dataset\n",
    "- **Test Set**: FLEURS Hindi (google/fleurs, hi_in split)\n",
    "- **Number of Samples**: {baseline_results['num_samples']}\n",
    "\n",
    "## Models Evaluated\n",
    "1. **Baseline**: {CONFIG['baseline_model']}\n",
    "2. **Fine-tuned**: {CONFIG['finetuned_model']}\n",
    "\n",
    "## Results\n",
    "\n",
    "| Model | WER (%) |\n",
    "|-------|--------|\n",
    "| Baseline (whisper-small) | {baseline_results['wer']:.2f} |\n",
    "| Fine-tuned (whisper-hindi) | {finetuned_results['wer']:.2f} |\n",
    "\n",
    "## Performance Improvement\n",
    "- **Absolute WER Reduction**: {wer_improvement:.2f} percentage points\n",
    "- **Relative Improvement**: {relative_improvement:.2f}%\n",
    "\n",
    "## Conclusion\n",
    "The fine-tuned model {'improved' if wer_improvement > 0 else 'did not improve'} over the baseline model on the FLEURS Hindi test set.\n",
    "\n",
    "---\n",
    "Generated using evaluation_pipeline.ipynb\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{CONFIG['results_dir']}/evaluation_report.md\", 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"\\n✓ Final report saved to:\", f\"{CONFIG['results_dir']}/evaluation_report.md\")\n",
    "print(\"\\n\" + report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T07:33:06.465987Z",
     "iopub.status.busy": "2025-11-02T07:33:06.465433Z",
     "iopub.status.idle": "2025-11-02T07:33:06.799376Z",
     "shell.execute_reply": "2025-11-02T07:33:06.798542Z",
     "shell.execute_reply.started": "2025-11-02T07:33:06.465958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3967788d4a554c56b99fbbefe058cfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "wer_comparison.csv:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4889cb1adf54474ea3de8e493b256ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "detailed_predictions.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded artifacts from Hugging Face dataset repo:\n",
      "- ../artifacts/hf_downloads/results/wer_comparison.csv\n",
      "- ../artifacts/hf_downloads/results/detailed_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "download_cache = Path(\"../artifacts/hf_downloads\")\n",
    "download_cache.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hf_comparison_path = hf_hub_download(\n",
    "    repo_id=repo_id,\n",
    "    repo_type=repo_type,\n",
    "    filename=\"results/wer_comparison.csv\",\n",
    "    token=token,\n",
    "    local_dir=download_cache\n",
    " )\n",
    "hf_detailed_path = hf_hub_download(\n",
    "    repo_id=repo_id,\n",
    "    repo_type=repo_type,\n",
    "    filename=\"results/detailed_predictions.csv\",\n",
    "    token=token,\n",
    "    local_dir=download_cache\n",
    " )\n",
    "\n",
    "hf_comparison_df = pd.read_csv(hf_comparison_path)\n",
    "hf_detailed_results = pd.read_csv(hf_detailed_path)\n",
    "\n",
    "print(\"Loaded artifacts from Hugging Face dataset repo:\")\n",
    "print(f\"- {hf_comparison_path}\")\n",
    "print(f\"- {hf_detailed_path}\")\n",
    "\n",
    "# Optional: clean up HF cache directory to avoid stale files on reruns\n",
    "shutil.rmtree(download_cache, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T07:33:18.387241Z",
     "iopub.status.busy": "2025-11-02T07:33:18.386528Z",
     "iopub.status.idle": "2025-11-02T07:33:19.539464Z",
     "shell.execute_reply": "2025-11-02T07:33:19.538811Z",
     "shell.execute_reply.started": "2025-11-02T07:33:18.387213Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evaluation graphs based on Hugging Face data:\n",
      "- wer_comparison.png\n",
      "- wer_distribution.png\n",
      "- top_wer_improvements.png\n",
      "- length_vs_improvement.png\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from jiwer import wer as jiwer_wer\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "graphs_dir = Path(\"../graphs\")\n",
    "graphs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if 'hf_detailed_results' not in globals() or 'hf_comparison_df' not in globals():\n",
    "    raise RuntimeError(\"Run the Hugging Face download cell before generating plots.\")\n",
    "\n",
    "analysis_df = hf_detailed_results.copy()\n",
    "analysis_df[\"reference\"] = analysis_df[\"reference\"].fillna(\"\")\n",
    "analysis_df[\"baseline_prediction\"] = analysis_df[\"baseline_prediction\"].fillna(\"\")\n",
    "analysis_df[\"finetuned_prediction\"] = analysis_df[\"finetuned_prediction\"].fillna(\"\")\n",
    "\n",
    "analysis_df[\"reference_word_count\"] = (\n",
    "    analysis_df[\"reference\"].str.split().str.len().fillna(0).astype(int)\n",
    ")\n",
    "\n",
    "def safe_wer(reference: str, hypothesis: str) -> float:\n",
    "    reference = reference or \"\"\n",
    "    hypothesis = hypothesis or \"\"\n",
    "    if not reference.strip():\n",
    "        return np.nan\n",
    "    return float(jiwer_wer(reference, hypothesis))\n",
    "\n",
    "analysis_df[\"baseline_wer\"] = analysis_df.apply(\n",
    "    lambda row: safe_wer(row[\"reference\"], row[\"baseline_prediction\"]), axis=1\n",
    ")\n",
    "analysis_df[\"finetuned_wer\"] = analysis_df.apply(\n",
    "    lambda row: safe_wer(row[\"reference\"], row[\"finetuned_prediction\"]), axis=1\n",
    ")\n",
    "analysis_df[\"wer_improvement\"] = analysis_df[\"baseline_wer\"] - analysis_df[\"finetuned_wer\"]\n",
    "\n",
    "comparison_df = hf_comparison_df.copy()\n",
    "comparison_df[\"WER (%)\"] = pd.to_numeric(comparison_df[\"WER (%)\"], errors=\"coerce\")\n",
    "baseline_row = comparison_df[comparison_df[\"Model\"].str.contains(\"Baseline\", case=False, na=False)]\n",
    "finetuned_row = comparison_df[comparison_df[\"Model\"].str.contains(\"Fine\", case=False, na=False)]\n",
    "\n",
    "if baseline_row.empty or finetuned_row.empty:\n",
    "    raise RuntimeError(\"Could not locate baseline/fine-tuned rows in the comparison table.\")\n",
    "baseline_wer = float(baseline_row.iloc[0][\"WER (%)\"])\n",
    "finetuned_wer = float(finetuned_row.iloc[0][\"WER (%)\"])\n",
    "\n",
    "saved_plots: list[str] = []\n",
    "\n",
    "# 1. Overall WER comparison\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "models = [\"Baseline\", \"Fine-tuned\"]\n",
    "wer_values = [baseline_wer, finetuned_wer]\n",
    "bars = ax.bar(models, wer_values, color=[\"#d62728\", \"#2ca02c\"])\n",
    "ax.set_ylabel(\"WER (%)\")\n",
    "ax.set_title(\"Word Error Rate Comparison (Hub Data)\")\n",
    "for bar, value in zip(bars, wer_values):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, value + 0.5, f\"{value:.2f}\", ha=\"center\", va=\"bottom\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(graphs_dir / \"wer_comparison.png\", dpi=200)\n",
    "plt.close(fig)\n",
    "saved_plots.append(\"wer_comparison.png\")\n",
    "\n",
    "# 2. Per-sample WER distribution\n",
    "valid_mask = analysis_df[[\"baseline_wer\", \"finetuned_wer\"]].notna().all(axis=1)\n",
    "if valid_mask.any():\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.hist(\n",
    "        analysis_df.loc[valid_mask, \"baseline_wer\"] * 100,\n",
    "        bins=30,\n",
    "        alpha=0.6,\n",
    "        label=\"Baseline\",\n",
    "        color=\"#ff7f0e\"\n",
    "    )\n",
    "    ax.hist(\n",
    "        analysis_df.loc[valid_mask, \"finetuned_wer\"] * 100,\n",
    "        bins=30,\n",
    "        alpha=0.6,\n",
    "        label=\"Fine-tuned\",\n",
    "        color=\"#1f77b4\"\n",
    "    )\n",
    "    ax.set_xlabel(\"Per-sample WER (%)\")\n",
    "    ax.set_ylabel(\"Number of Utterances\")\n",
    "    ax.set_title(\"Distribution of Per-sample WER (Hub Data)\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(graphs_dir / \"wer_distribution.png\", dpi=200)\n",
    "    plt.close(fig)\n",
    "    saved_plots.append(\"wer_distribution.png\")\n",
    "\n",
    "# 3. Top improvements\n",
    "if analysis_df[\"wer_improvement\"].notna().any():\n",
    "    top_improvements = analysis_df.sort_values(\"wer_improvement\", ascending=False).head(20)\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    improvement_percent = top_improvements[\"wer_improvement\"] * 100\n",
    "    bars = ax.barh(range(len(top_improvements)), improvement_percent, color=\"#2ca02c\")\n",
    "    ax.set_yticks(range(len(top_improvements)))\n",
    "    ax.set_yticklabels([f\"Sample {idx}\" for idx in top_improvements.index])\n",
    "    ax.set_xlabel(\"WER Improvement (percentage points)\")\n",
    "    ax.set_title(\"Top 20 Utterances with Largest WER Gains (Hub Data)\")\n",
    "    ax.invert_yaxis()\n",
    "    for bar, value in zip(bars, improvement_percent):\n",
    "        ax.text(value + 0.2, bar.get_y() + bar.get_height() / 2, f\"{value:.2f}\", va=\"center\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(graphs_dir / \"top_wer_improvements.png\", dpi=200)\n",
    "    plt.close(fig)\n",
    "    saved_plots.append(\"top_wer_improvements.png\")\n",
    "\n",
    "# 4. Reference length vs improvement\n",
    "if analysis_df[\"reference_word_count\"].notna().any() and analysis_df[\"wer_improvement\"].notna().any():\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    scatter = ax.scatter(\n",
    "        analysis_df[\"reference_word_count\"],\n",
    "        analysis_df[\"wer_improvement\"] * 100,\n",
    "        c=analysis_df[\"wer_improvement\"] * 100,\n",
    "        cmap=\"RdYlGn\",\n",
    "        alpha=0.7\n",
    "    )\n",
    "    ax.set_xlabel(\"Reference Word Count\")\n",
    "    ax.set_ylabel(\"WER Improvement (percentage points)\")\n",
    "    ax.set_title(\"Effect of Utterance Length on WER Improvement (Hub Data)\")\n",
    "    fig.colorbar(scatter, ax=ax, label=\"WER Improvement (pp)\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(graphs_dir / \"length_vs_improvement.png\", dpi=200)\n",
    "    plt.close(fig)\n",
    "    saved_plots.append(\"length_vs_improvement.png\")\n",
    "\n",
    "print(\"Saved evaluation graphs based on Hugging Face data:\")\n",
    "for name in saved_plots:\n",
    "    print(f\"- {name}\")\n",
    "if not saved_plots:\n",
    "    print(\"(No plots generated — check input data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T07:35:05.541001Z",
     "iopub.status.busy": "2025-11-02T07:35:05.540468Z",
     "iopub.status.idle": "2025-11-02T07:35:10.415018Z",
     "shell.execute_reply": "2025-11-02T07:35:10.414431Z",
     "shell.execute_reply.started": "2025-11-02T07:35:05.540978Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f8b3a2143648cbb12918bf2aa79f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2c9b8d4d894ef1a9dd304edf504a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded ../graphs/length_vs_improvement.png to hf://datafreak/whisper-hindi-eval-results/graphs/length_vs_improvement.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e5e7ba36eb4d8ab70671660e61ff4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c257f25c78fb44d88e2e2ad9ba26b455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded ../graphs/top_wer_improvements.png to hf://datafreak/whisper-hindi-eval-results/graphs/top_wer_improvements.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3eb85971d6429f9be9a4e2dd36c295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e750630ba0e1419188c55018e0fbc0c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded ../graphs/wer_comparison.png to hf://datafreak/whisper-hindi-eval-results/graphs/wer_comparison.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb8bf21022549a492acc12e987a24fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb35d0fa6f54275b7320378cc7e8811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded ../graphs/wer_distribution.png to hf://datafreak/whisper-hindi-eval-results/graphs/wer_distribution.png\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "graphs_dir = Path(\"../graphs\")\n",
    "if not graphs_dir.exists():\n",
    "    raise FileNotFoundError(\"Graphs directory not found. Run the visualization cell before uploading charts.\")\n",
    "\n",
    "image_paths = sorted(graphs_dir.glob(\"*.png\"))\n",
    "if not image_paths:\n",
    "    raise FileNotFoundError(\"No PNG files detected in ../graphs. Generate the plots first.\")\n",
    "\n",
    "for image_path in image_paths:\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=image_path,\n",
    "        path_in_repo=f\"graphs/{image_path.name}\",\n",
    "        repo_id=repo_id,\n",
    "        repo_type=repo_type,\n",
    "        token=token\n",
    "    )\n",
    "    print(f\"✓ Uploaded {image_path} to hf://{repo_id}/graphs/{image_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "1. ✓ Loaded the FLEURS Hindi test dataset\n",
    "2. ✓ Evaluated the baseline Whisper-small model\n",
    "3. ✓ Evaluated the fine-tuned model from Hugging Face\n",
    "4. ✓ Compared the results\n",
    "5. ✓ Generated a detailed report\n",
    "\n",
    "All results have been saved to the `results/` directory."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
