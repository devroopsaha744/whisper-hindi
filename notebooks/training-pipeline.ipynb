{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper-Small Hindi Fine-tuning Pipeline\n",
    "\n",
    "This notebook fine-tunes the Whisper-small model on Hindi ASR data and pushes it to Hugging Face Hub.\n",
    "\n",
    "## Steps:\n",
    "1. Load and preprocess the dataset\n",
    "2. Setup Whisper model and feature extractor\n",
    "3. Create data collator and training arguments\n",
    "4. Fine-tune the model\n",
    "5. Push to Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T19:00:53.267108Z",
     "iopub.status.busy": "2025-11-01T19:00:53.266811Z",
     "iopub.status.idle": "2025-11-01T19:02:13.577669Z",
     "shell.execute_reply": "2025-11-01T19:02:13.576935Z",
     "shell.execute_reply.started": "2025-11-01T19:00:53.267089Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets accelerate evaluate jiwer huggingface-hub soundfile librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T19:02:16.994948Z",
     "iopub.status.busy": "2025-11-01T19:02:16.994389Z",
     "iopub.status.idle": "2025-11-01T19:02:46.458808Z",
     "shell.execute_reply": "2025-11-01T19:02:46.457961Z",
     "shell.execute_reply.started": "2025-11-01T19:02:16.994919Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 19:02:29.781736: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762023749.997164      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762023750.059468      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import librosa  # <-- ADDED THIS\n",
    "from datasets import Dataset, Audio\n",
    "from transformers import (\n",
    "    WhisperFeatureExtractor,\n",
    "    WhisperTokenizer,\n",
    "    WhisperProcessor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "import evaluate\n",
    "from huggingface_hub import HfApi, login\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T19:02:46.460444Z",
     "iopub.status.busy": "2025-11-01T19:02:46.459926Z",
     "iopub.status.idle": "2025-11-01T19:02:46.630560Z",
     "shell.execute_reply": "2025-11-01T19:02:46.629800Z",
     "shell.execute_reply.started": "2025-11-01T19:02:46.460425Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Logged in to Hugging Face Hub\n",
      "Using device: cuda\n",
      "GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'model_name': 'openai/whisper-small',\n",
    "    'language': 'hindi',\n",
    "    'language_code': 'hi',\n",
    "    'task': 'transcribe',\n",
    "    'data_dir': '/kaggle/input/whisper-hindhi/data', # Corrected this path\n",
    "    'output_dir': '/kaggle/working/models/whisper-small-hindi',   \n",
    "    'hf_repo': 'datafreak/whisper-hindi',\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    'learning_rate': 1e-5,\n",
    "    'batch_size': 4,\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'num_epochs': 3,\n",
    "    'warmup_steps': 500,\n",
    "    'max_duration': 30.0,\n",
    "    'eval_steps': 500,\n",
    "    'save_steps': 500,\n",
    "    'logging_steps': 100,\n",
    "    \n",
    "    # Data processing\n",
    "    'sampling_rate': 16000,\n",
    "    'train_split': 0.95,\n",
    "    'max_label_length': 448,\n",
    "}\n",
    "\n",
    "# Get HuggingFace token\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\", \"<HF_TOKEN_PLACEHOLDER>\")\n",
    "if HF_TOKEN and HF_TOKEN != \"<HF_TOKEN_PLACEHOLDER>\":\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"✓ Logged in to Hugging Face Hub\")\n",
    "else:\n",
    "    print(\"⚠ HF_TOKEN not provided. Set the environment variable before pushing to Hub.\")\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T19:02:50.114716Z",
     "iopub.status.busy": "2025-11-01T19:02:50.114428Z",
     "iopub.status.idle": "2025-11-01T19:02:50.124459Z",
     "shell.execute_reply": "2025-11-01T19:02:50.123635Z",
     "shell.execute_reply.started": "2025-11-01T19:02:50.114694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def load_downloaded_data(data_dir):\n",
    "    data_dir = Path(data_dir)\n",
    "    base_dir = data_dir.parent \n",
    "    \n",
    "    results_file = data_dir / 'download_results.csv'\n",
    "\n",
    "    if not results_file.exists():\n",
    "        print(f\"Error: 'download_results.csv' not found at {results_file}\")\n",
    "        return []\n",
    "\n",
    "    df = pd.read_csv(results_file)\n",
    "    print(f\"Found {len(df)} total rows in download_results.csv\")\n",
    "\n",
    "    df = df[(df['audio_success'] == True) & (df['transcription_success'] == True)]\n",
    "    print(f\"Found {len(df)} rows after filtering for success=True\")\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        print(\"No successful rows to process. Stopping.\")\n",
    "        return []\n",
    "\n",
    "    # --- THIS IS THE NEW LOGIC ---\n",
    "    data = []\n",
    "    for index, row in df.iterrows():\n",
    "        csv_audio_path = str(row['audio_path']).replace('\\\\', '/')\n",
    "        audio_path = base_dir / csv_audio_path\n",
    "        csv_trans_path = str(row['transcription_path']).replace('\\\\', '/')\n",
    "        trans_path = base_dir / csv_trans_path\n",
    "\n",
    "        if not audio_path.exists() or not trans_path.exists():\n",
    "            print(f\"--- SKIPPING ROW {index}: File not found ---\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Load the transcription file\n",
    "            with open(trans_path, 'r', encoding='utf-8') as f:\n",
    "                raw_transcription = f.read().strip()\n",
    "            \n",
    "            # Parse the JSON (assuming it's a list of segments as you showed)\n",
    "            segments = json.loads(raw_transcription)\n",
    "            \n",
    "            # Handle cases where it's a dict like {'segments': [...]}\n",
    "            if isinstance(segments, dict) and 'segments' in segments:\n",
    "                segments = segments['segments']\n",
    "            \n",
    "            # Ensure segments is a list\n",
    "            if not isinstance(segments, list):\n",
    "                print(f\"--- SKIPPING ROW {index}: Tx format not a list of segments ---\")\n",
    "                continue\n",
    "\n",
    "            # NOW, create one entry FOR EACH SEGMENT\n",
    "            for seg in segments:\n",
    "                if 'text' in seg and 'start' in seg and 'end' in seg:\n",
    "                    text = seg['text'].strip()\n",
    "                    start_time = float(seg['start'])\n",
    "                    end_time = float(seg['end'])\n",
    "                    \n",
    "                    # Ignore empty segments\n",
    "                    if not text or text == \"REDACTED\":\n",
    "                        continue\n",
    "                        \n",
    "                    data.append({\n",
    "                        'audio_path': str(audio_path), # Path to the full audio\n",
    "                        'start_time': start_time,      # Start of this chunk\n",
    "                        'end_time': end_time,        # End of this chunk\n",
    "                        'transcription': text          # Text for *only* this chunk\n",
    "                    })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"--- SKIPPING ROW {index}: Error parsing {trans_path}: {e} ---\")\n",
    "    # --- END OF NEW LOGIC ---\n",
    "\n",
    "    print(f\"\\nLoaded {len(data)} individual segments (chunks) from {len(df)} files\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T19:02:54.034627Z",
     "iopub.status.busy": "2025-11-01T19:02:54.034036Z",
     "iopub.status.idle": "2025-11-01T19:02:54.871032Z",
     "shell.execute_reply": "2025-11-01T19:02:54.870196Z",
     "shell.execute_reply.started": "2025-11-01T19:02:54.034602Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 104 total rows in download_results.csv\n",
      "Found 104 rows after filtering for success=True\n",
      "\n",
      "Loaded 5732 individual segments (chunks) from 104 files\n"
     ]
    }
   ],
   "source": [
    "data = load_downloaded_data(CONFIG['data_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T19:02:59.107331Z",
     "iopub.status.busy": "2025-11-01T19:02:59.106742Z",
     "iopub.status.idle": "2025-11-01T19:02:59.143905Z",
     "shell.execute_reply": "2025-11-01T19:02:59.143118Z",
     "shell.execute_reply.started": "2025-11-01T19:02:59.107306Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train chunks: 5445, Val chunks: 287\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check if data loading failed\n",
    "if len(df) == 0:\n",
    "    raise ValueError(\"Data loading resulted in 0 samples. Cannot proceed.\")\n",
    "\n",
    "train_size = int(len(df) * CONFIG['train_split'])\n",
    "train_df = df[:train_size]\n",
    "val_df = df[train_size:]\n",
    "\n",
    "# Create dataset from pandas WITHOUT casting the audio column\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "print(f\"Train chunks: {len(train_dataset)}, Val chunks: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup Model Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T19:03:01.539633Z",
     "iopub.status.busy": "2025-11-01T19:03:01.539365Z",
     "iopub.status.idle": "2025-11-01T19:15:56.083551Z",
     "shell.execute_reply": "2025-11-01T19:15:56.082949Z",
     "shell.execute_reply.started": "2025-11-01T19:03:01.539614Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea72eda178f648e389ee0e1af18c1e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6063ed2f2cc84ea4b1486a5ad1db06cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955c57101c89461799bb79ac92089ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf3f1456eb44d3180f3265344bd0c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac16912616f45499d5c69dc7ba3a5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e295a253ec784d95824d028ddcb6c446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f675e2e6980b4ddfba72f11b647538a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdcf05d268d4a708693cbf016a5cb0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping train dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52d1046bac4495c97ba176b61cf9df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5445 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping validation dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac2726a8f504bc58ff116e1ae2d084d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f8f2f9b91b48fda9be3cd1500d59c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5445 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f623d0bde94cbe9d3f62b055479a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dataset after mapping and filtering ---\n",
      "Train samples remaining: 5445\n",
      "Validation samples remaining: 287\n",
      "Dataset({\n",
      "    features: ['input_features', 'labels'],\n",
      "    num_rows: 5445\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_features', 'labels'],\n",
      "    num_rows: 287\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(CONFIG['model_name'])\n",
    "tokenizer = WhisperTokenizer.from_pretrained(CONFIG['model_name'], language='hindi', task='transcribe')\n",
    "processor = WhisperProcessor.from_pretrained(CONFIG['model_name'], language='hindi', task='transcribe')\n",
    "\n",
    "MAX_DURATION_SEC = CONFIG['max_duration']\n",
    "MAX_LABEL_LENGTH = CONFIG['max_label_length']\n",
    "SAMPLING_RATE = CONFIG['sampling_rate']\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    try:\n",
    "        # Load the *entire* audio file\n",
    "        # We use 'offset' and 'duration' to load only the part we need\n",
    "        start_time = batch['start_time']\n",
    "        end_time = batch['end_time']\n",
    "        duration = end_time - start_time\n",
    "        \n",
    "        # --- FILTERING ---\n",
    "        # 1. Check audio duration from timestamps\n",
    "        if duration > MAX_DURATION_SEC:\n",
    "            print(f\"SKIPPING: Segment duration {duration}s > {MAX_DURATION_SEC}s\")\n",
    "            return {\"input_features\": None, \"labels\": None}\n",
    "\n",
    "        # Load only the required audio chunk\n",
    "        audio_array, sampling_rate = librosa.load(\n",
    "            batch[\"audio_path\"], \n",
    "            sr=SAMPLING_RATE, \n",
    "            offset=start_time, \n",
    "            duration=duration\n",
    "        )\n",
    "        \n",
    "        # 2. Check text length\n",
    "        tokenized_labels = tokenizer(batch[\"transcription\"]).input_ids\n",
    "        if len(tokenized_labels) > MAX_LABEL_LENGTH:\n",
    "            print(f\"SKIPPING: Text length {len(tokenized_labels)} > {MAX_LABEL_LENGTH}\")\n",
    "            return {\"input_features\": None, \"labels\": None}\n",
    "        # --- END OF FILTERING ---\n",
    "\n",
    "        # If both are fine, process the audio\n",
    "        batch[\"input_features\"] = feature_extractor(audio_array, sampling_rate=SAMPLING_RATE).input_features[0]\n",
    "        batch[\"labels\"] = tokenized_labels\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing segment from {batch['audio_path']} ({batch['start_time']}s): {e}\")\n",
    "        batch[\"input_features\"] = None\n",
    "        batch[\"labels\"] = None\n",
    "        \n",
    "    return batch\n",
    "\n",
    "print(\"Mapping train dataset...\")\n",
    "train_dataset = train_dataset.map(\n",
    "    prepare_dataset, \n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "print(\"Mapping validation dataset...\")\n",
    "val_dataset = val_dataset.map(\n",
    "    prepare_dataset, \n",
    "    remove_columns=val_dataset.column_names\n",
    ")\n",
    "\n",
    "# Filter out all the samples that were marked for skipping\n",
    "train_dataset = train_dataset.filter(lambda example: example[\"input_features\"] is not None)\n",
    "val_dataset = val_dataset.filter(lambda example: example[\"input_features\"] is not None)\n",
    "\n",
    "print(\"--- Dataset after mapping and filtering ---\")\n",
    "print(f\"Train samples remaining: {len(train_dataset)}\")\n",
    "print(f\"Validation samples remaining: {len(val_dataset)}\")\n",
    "print(train_dataset)\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Collator & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T19:16:09.689776Z",
     "iopub.status.busy": "2025-11-01T19:16:09.689041Z",
     "iopub.status.idle": "2025-11-01T19:16:10.416547Z",
     "shell.execute_reply": "2025-11-01T19:16:10.415827Z",
     "shell.execute_reply.started": "2025-11-01T19:16:09.689751Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470cd87e2bd34b02a5af2279d2c7ff35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=tokenizer.bos_token_id,\n",
    ")\n",
    "\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Model & Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T19:16:14.254577Z",
     "iopub.status.busy": "2025-11-01T19:16:14.254023Z",
     "iopub.status.idle": "2025-11-01T19:16:19.672285Z",
     "shell.execute_reply": "2025-11-01T19:16:19.671458Z",
     "shell.execute_reply.started": "2025-11-01T19:16:14.254553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f8c4f8630f418192dbb2021e7866d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13c36e1b1c0478ca7f3a16a37b3ca38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1caa2ddd4c421481521a91418c6633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(CONFIG['model_name'])\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "model.config.use_cache = False\n",
    "model.generation_config.language = 'hi'\n",
    "model.generation_config.task = 'transcribe'\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=CONFIG['output_dir'],\n",
    "    per_device_train_batch_size=CONFIG['batch_size'],\n",
    "    per_device_eval_batch_size=CONFIG['batch_size'],\n",
    "    gradient_accumulation_steps=CONFIG['gradient_accumulation_steps'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    warmup_steps=CONFIG['warmup_steps'],\n",
    "    num_train_epochs=CONFIG['num_epochs'],\n",
    "    \n",
    "    # RENAMED from evaluation_strategy to eval_strategy\n",
    "    eval_strategy=\"steps\", \n",
    "    eval_steps=CONFIG['eval_steps'],\n",
    "    \n",
    "    # Explicitly set save_strategy to match\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=CONFIG['save_steps'],\n",
    "    \n",
    "    logging_steps=CONFIG['logging_steps'],\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=[\"tensorboard\"],\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=448,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T19:16:25.814955Z",
     "iopub.status.busy": "2025-11-01T19:16:25.814340Z",
     "iopub.status.idle": "2025-11-01T21:14:07.211672Z",
     "shell.execute_reply": "2025-11-01T21:14:07.210693Z",
     "shell.execute_reply.started": "2025-11-01T19:16:25.814929Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1023' max='1023' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1023/1023 1:57:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.338400</td>\n",
       "      <td>0.382823</td>\n",
       "      <td>43.531094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.323355</td>\n",
       "      <td>37.080057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete! Loss: 0.4620\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "train_result = trainer.train()\n",
    "print(f\"Training complete! Loss: {train_result.metrics['train_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T21:14:15.342682Z",
     "iopub.status.busy": "2025-11-01T21:14:15.342037Z",
     "iopub.status.idle": "2025-11-01T21:18:39.489435Z",
     "shell.execute_reply": "2025-11-01T21:18:39.488776Z",
     "shell.execute_reply.started": "2025-11-01T21:14:15.342657Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation WER: 37.08%\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Validation WER: {eval_results['eval_wer']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save & Push to Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T21:18:48.553752Z",
     "iopub.status.busy": "2025-11-01T21:18:48.553136Z",
     "iopub.status.idle": "2025-11-01T21:19:13.349857Z",
     "shell.execute_reply": "2025-11-01T21:19:13.349175Z",
     "shell.execute_reply.started": "2025-11-01T21:18:48.553730Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushing to datafreak/whisper-hindi...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df45ae130994a65971f83f6694a2530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725139d6951d48fab8e218345e5fde78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6febdea751be4a9582e46bcd718ad046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model pushed to https://huggingface.co/datafreak/whisper-hindi\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(CONFIG['output_dir'])\n",
    "processor.save_pretrained(CONFIG['output_dir'])\n",
    "\n",
    "if HF_TOKEN and HF_TOKEN != \"<HF_TOKEN_PLACEHOLDER>\":\n",
    "    print(f\"Pushing to {CONFIG['hf_repo']}...\")\n",
    "    model.push_to_hub(CONFIG['hf_repo'], token=HF_TOKEN)\n",
    "    processor.push_to_hub(CONFIG['hf_repo'], token=HF_TOKEN)\n",
    "    print(f\"✓ Model pushed to https://huggingface.co/{CONFIG['hf_repo']}\")\n",
    "else:\n",
    "    print(\"⚠ HF_TOKEN not set. Skipping push to Hub.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8610360,
     "sourceId": 13556143,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
